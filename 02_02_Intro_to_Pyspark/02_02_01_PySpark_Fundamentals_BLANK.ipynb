{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08694c06",
   "metadata": {
    "id": "08694c06"
   },
   "source": [
    "<center>\n",
    "    <img src=\"https://rockborne.com/wp-content/uploads/2021/07/LandingPage-Header-RED-CENTRE.jpg\" width=\"900\" alt=\"logo\"  />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t4Ogd05gtKIm",
   "metadata": {
    "id": "t4Ogd05gtKIm"
   },
   "source": [
    "---\n",
    "# Introduction to PySpark\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5F_z6qcvF11G",
   "metadata": {
    "id": "5F_z6qcvF11G"
   },
   "source": [
    "\n",
    "# Prerequisites\n",
    "\n",
    "- Have the following data downloaded:\n",
    "  - `people.json`\n",
    "  - `appl-stock.csv`\n",
    "  - `Production.Product.csv`\n",
    "  - `superstore.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wtwYY6Atu1GU",
   "metadata": {
    "id": "wtwYY6Atu1GU"
   },
   "source": [
    "<a name=\"anchorWhatIsSpark\" style=\"position:absolute;\"></a>\n",
    "<hr style=\"border:2px solid\">\n",
    "\n",
    "# 1. Introduction\n",
    "<hr style=\"border-top:1px dashed\">\n",
    "\n",
    "This notebook will guide you through the basics of using PySpark for data analysis.  \n",
    "\n",
    "We will work with a dataset containing student marks across different modules.  \n",
    "\n",
    "You'll learn how to:  \n",
    "- Load and explore data using PySpark  \n",
    "- Perform basic transformations  \n",
    "\n",
    "Throughout the notebook, you’ll find **tasks** to complete on your own to reinforce your understanding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h0VsIrPuqFeQ",
   "metadata": {
    "id": "h0VsIrPuqFeQ"
   },
   "source": [
    "---\n",
    "\n",
    "## **What is Apache Spark?**\n",
    "Apache Spark is a powerful big data processing engine focused on:\n",
    "- **Speed**\n",
    "- **Ease of Use**\n",
    "- **Modularity**\n",
    "- **Extensibility**\n",
    "\n",
    "Spark provides in-memory storage for intermediate computations, making it much faster than Hadoop MapReduce. The Spark engine includes libraries accessible via APIs in Python, R, and Scala. It supports multiple deployment environments and integrates with various data sources.\n",
    "\n",
    "### **Apache Spark Architecture**\n",
    "Spark uses a **Directed Acyclic Graph (DAG)** for computation, which allows it to efficiently process tasks in parallel.\n",
    "\n",
    "### **Apache Spark Ecosystem**\n",
    "![Spark Ecosystem](https://www.oreilly.com/api/v2/epubs/9781787283985/files/assets/2581d347-d9db-4b1e-96f5-914e3f5e77fb.png)\n",
    "\n",
    "*Reference: [O'Reilly](https://www.oreilly.com/library/view/learning-spark-2nd/9781492050032/ch01.html)*\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **What is PySpark?**\n",
    "\n",
    "PySpark is the Python API for Apache Spark, allowing users to interact with Spark using Python syntax. It provides:\n",
    "- Distributed computing capabilities\n",
    "- Data processing at scale\n",
    "- Seamless integration with Python libraries\n",
    "\n",
    "PySpark operates by interfacing with the **Java Virtual Machine (JVM)** using the `Py4J` package, meaning Java must be installed.\n",
    "\n",
    "### **PySpark Architecture**\n",
    "- **Driver Node**: The entry point to the application\n",
    "- **Worker Nodes**: Execute tasks in parallel\n",
    "- **Cluster Manager**: Handles resource allocation\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://spark.apache.org/docs/latest/img/cluster-overview.png\" width=\"500\" alt=\"PySpark Arch\"  />\n",
    "</center>\n",
    "\n",
    "Reference: https://spark.apache.org/docs/latest/cluster-overview.html\n",
    "\n",
    "\n",
    "### **Spark Workloads**\n",
    "Spark is well-suited for:\n",
    "- **ETL (Extract, Transform, Load)** (Batch & Streaming)\n",
    "- **Interactive Queries** (Spark SQL)\n",
    "- **Machine Learning** (MLlib)\n",
    "- **Graph Processing** (GraphX/GraphFrames)\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://www.researchgate.net/profile/Josh-Choi-2/publication/303098621/figure/fig5/AS:566114846298112@1511983705187/The-Apache-Spark-TM-stack-of-engine-bottom-and-libraries-top-Image-credit.png\" width=\"500\" alt=\"Spark Core\"  />\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "\n",
    "[Reference](https://www.researchgate.net/publication/272825265_Big_Data_Analysis_Apache_Spark_Perspective)\n",
    "\n",
    "\n",
    "### **Concepts and Key Terms**\n",
    "\n",
    "\n",
    "<strong>Spark Cluster</strong>\n",
    "<p>A collection of machines or nodes in the cloud or on-premise in a data center on which Spark is installed. Among those machines are Spark workers, a Spark Master (also a cluster manager in a Standalone mode), and at least one Spark Driver.</p>\n",
    "\n",
    "<strong>Spark Master</strong>\n",
    "<p>As the name suggests, Spark master JVM acts as a cluster manager in a Standalone deployment mode to which Spark workers register themselves as part of a quorum. Depending on the deployment  mode, it acts as a resource manager and decides where and how many Executors to launch, and on what Spark workers in the cluster.</p>\n",
    "\n",
    "<strong>Spark Worker</strong>\n",
    "<p>The Spark worker JVM, upon receiving instructions from Spark master, launches executors on the worker on behalf of the Spark driver. Spark applications, decomposed into units of tasks, are executed on each worker’s Executor. In short, the worker’s job is to only launch an Executor on behalf of the master.</p>\n",
    "\n",
    "<strong>Spark Executor</strong>\n",
    "<p>It’s a JVM container with an allocated amount of cores and memory on which Spark runs its tasks. Each worker node launches its own Spark Executor, with a configurable number of cores (or threads). Besides executing Spark tasks, an Executor also stores and caches all data partitions in memory.</p>\n",
    "\n",
    "<strong>Spark Driver</strong>\n",
    "<p>Once it gets information from the Spark master of all the workers in the cluster and where they are, the driver program distributes Spark tasks to each worker’s Executor. The driver also receives computed results from each Executor’s tasks.</p>\n",
    "\n",
    "![Spark Cluster](https://datacadamia.com/_media/db/spark/cluster/spark_cluster_tasks_slot.png)\n",
    "*Reference: DataCadamia*\n",
    "\n",
    "\n",
    "### **Why PySpark?**\n",
    "If you're familiar with Pandas, you might wonder why we need PySpark. Here are some key differences:\n",
    "\n",
    "| Feature        | Pandas (Single Machine) | PySpark (Distributed) |\n",
    "|---------------|------------------------|------------------------|\n",
    "| Data Size     | Limited by RAM          | Scales across clusters |\n",
    "| Performance   | Fast for small data     | Optimized for big data |\n",
    "| Parallelism   | Single-threaded         | Multi-threaded, parallel |\n",
    "| Storage       | Local memory/disk       | Distributed storage (HDFS, S3, etc.) |\n",
    "\n",
    "### **Example: Pandas vs. PySpark DataFrame Operations**\n",
    "\n",
    "#### **Pandas Example**\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head()\n",
    "```\n",
    "\n",
    "#### **PySpark Example**\n",
    "```python\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"example\").getOrCreate()\n",
    "df = spark.read.csv(\"data.csv\", header=True, inferSchema=True)\n",
    "df.show()\n",
    "```\n",
    "\n",
    "### **SQL to PySpark Translation**\n",
    "If you're comfortable with SQL, PySpark DataFrames work similarly. Here’s how common SQL queries translate to PySpark:\n",
    "\n",
    "#### **SQL Query**\n",
    "```sql\n",
    "-- SQL\n",
    "SELECT name, age FROM people WHERE age > 30;\n",
    "```\n",
    "\n",
    "#### **PySpark Equivalent**\n",
    "```python\n",
    "df.select(\"name\", \"age\").filter(df.age > 30).show()\n",
    "```\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "This notebook provides a fundamental understanding of PySpark. In the next sections, we'll explore:\n",
    "1. Setting up PySpark in Google Colab\n",
    "2. Loading and exploring data\n",
    "3. Transformations and actions in PySpark\n",
    "4. Aggregations and SQL queries in PySpark\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f9ba49",
   "metadata": {
    "id": "76f9ba49"
   },
   "source": [
    "<a name=\"anchorBasics\" style=\"position:absolute;\"></a>\n",
    "<hr style=\"border:2px solid\">\n",
    "\n",
    "# 2. PySpark Basics\n",
    "<hr style=\"border-top:1px dashed\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "qWj0n1r5pwVd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1741254584729,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "qWj0n1r5pwVd",
    "outputId": "df934911-896a-4c34-e584-e819c0c7feed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark-3.5.7-bin-hadoop3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start a SparkSession\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6987be57",
   "metadata": {
    "id": "6987be57"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b952aa47",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "executionInfo": {
     "elapsed": 13222,
     "status": "ok",
     "timestamp": 1741254600763,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "b952aa47",
    "outputId": "fa744384-9ea6-4961-c01f-0cd3ddf77123",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>TheBasics</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1aa0c16ef50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('TheBasics').getOrCreate() ##Create the session in the Spark server\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97960bf1",
   "metadata": {
    "id": "97960bf1"
   },
   "source": [
    "---\n",
    "<a name=\"anchorRDD\" style=\"position:absolute;\"></a>\n",
    "## 2.2 RDDs\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c17d4e",
   "metadata": {
    "id": "f0c17d4e"
   },
   "source": [
    "A feature in PySpark that you may not be used to working with in Python is a **Resilient Distributed Dataset** (RDD). RDDs are a fundamental data structure of PySpark that is **fault-tolerant and immutable** (meaning it cannot be changed). Each dataset in an RDD is divided into logical partitions which can be divided onto separate worker nodes for **faster computation**. RDDs are mostly suited towards **unstructured data** such as media streams or streams of text. They are also not bound by a columnar schema (like a dataframe in pandas is).\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://miro.medium.com/max/720/1*l2MUHFvWfcdiUbh7Y-fM5Q.png\" width=\"500\" alt=\"PySpark Intro\"  />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b273f26",
   "metadata": {
    "id": "7b273f26"
   },
   "source": [
    "### **Creating an RDD**\n",
    "There are several ways to create an RDD. Two such ways are the parallelize() function which will convert a list to an RDD and the textFile() function which will take a text file as the input and convert it into an RDD\n",
    "\n",
    "### **1. Using `parallelize()`**\n",
    "The `parallelize()` function takes an existing Python list and distributes it across the Spark cluster to form an RDD.\n",
    "\n",
    "#### **Example:**\n",
    "```python\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"RDD Example\").getOrCreate()\n",
    "sc = spark.sparkContext  # SparkContext is required for working with RDDs\n",
    "\n",
    "# Creating an RDD from a list\n",
    "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
    "print(rdd.collect())  # Output: [1, 2, 3, 4, 5]\n",
    "```\n",
    "\n",
    "### **2. Using `textFile()`**\n",
    "The `textFile()` function reads a text file and converts it into an RDD, where each line of the file becomes an element in the RDD.\n",
    "\n",
    "#### **Example:**\n",
    "```python\n",
    "# Creating an RDD from a text file\n",
    "rdd_text = sc.textFile(\"sample.txt\")\n",
    "print(rdd_text.collect())  # Output: ['line1', 'line2', 'line3', ...]\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FON20qACcvNo",
   "metadata": {
    "id": "FON20qACcvNo"
   },
   "source": [
    "Below, we will convert a standard Python list into a distributed RDD using PySpark's parallelize function. Once the data is in an RDD, we will apply transformations and actions to demonstrate PySpark's parallel processing capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "s1MqUQ__wm3W",
   "metadata": {
    "id": "s1MqUQ__wm3W"
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    (1, \"Alice\", \"Math\", 85),\n",
    "    (2, \"Bob\", \"Math\", 78),\n",
    "    (3, \"Charlie\", \"Math\", 92),\n",
    "    (4, \"Alice\", \"Science\", 88),\n",
    "    (5, \"Bob\", \"Science\", 74),\n",
    "    (6, \"Charlie\", \"Science\", 95),\n",
    "    (7, \"Alice\", \"History\", 90),\n",
    "    (8, \"Bob\", \"History\", 80),\n",
    "    (9, \"Charlie\", \"History\", 85)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uMRGzv0-4KYy",
   "metadata": {
    "id": "uMRGzv0-4KYy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rHctAS0s4NoL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1735,
     "status": "ok",
     "timestamp": 1741254886380,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "rHctAS0s4NoL",
    "outputId": "ad77e2c3-e48d-46c8-c919-a8a5474df0e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Alice', 'Math', 85),\n",
       " (2, 'Bob', 'Math', 78),\n",
       " (3, 'Charlie', 'Math', 92),\n",
       " (4, 'Alice', 'Science', 88),\n",
       " (5, 'Bob', 'Science', 74),\n",
       " (6, 'Charlie', 'Science', 95),\n",
       " (7, 'Alice', 'History', 90),\n",
       " (8, 'Bob', 'History', 80),\n",
       " (9, 'Charlie', 'History', 85)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "o82ojGKCuD-U",
   "metadata": {
    "id": "o82ojGKCuD-U"
   },
   "source": [
    "### **Transformations and Actions on RDDs**\n",
    "RDDs support two types of operations:\n",
    "- **Transformations**: These return a new RDD (lazy execution).\n",
    "- **Actions**: These return a value to the driver.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003da414",
   "metadata": {
    "id": "003da414"
   },
   "source": [
    "##### Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f450c7",
   "metadata": {
    "id": "99f450c7"
   },
   "source": [
    "Transformations return a new RDD without modifying the original.\n",
    "\n",
    "- **`map(func)`** – Applies `func` to each element and returns a new RDD.\n",
    "- **`flatMap(func)`** – Similar to `map`, but flattens the results.\n",
    "- **`filter(func)`** – Returns an RDD with elements that satisfy `func`.\n",
    "- **`distinct()`** – Removes duplicate elements.\n",
    "- **`sample(withReplacement, fraction)`** – Returns a sampled subset.\n",
    "- **`union(otherRDD)`** – Merges two RDDs.\n",
    "- **`intersection(otherRDD)`** – Returns common elements between RDDs.\n",
    "- **`subtract(otherRDD)`** – Returns elements in this RDD but not in `otherRDD`.\n",
    "- **`cartesian(otherRDD)`** – Returns the Cartesian product.\n",
    "- **`groupByKey()`** – Groups values with the same key (for `(K, V)` pairs).\n",
    "- **`reduceByKey(func)`** – Merges values with the same key using `func`.\n",
    "- **`sortByKey()`** – Sorts by key in an RDD of key-value pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VeaIzlk3NLnt",
   "metadata": {
    "id": "VeaIzlk3NLnt"
   },
   "source": [
    "#### **Lambda Functions in Python**\n",
    "Below we will also be using lambda functions. A **lambda function** is an **anonymous, single-expression function** defined using the `lambda` keyword instead of `def`. It is useful for short, simple functions.\n",
    "\n",
    "##### **Syntax:**\n",
    "```python\n",
    "lambda arguments: expression\n",
    "```\n",
    "\n",
    "##### **Example 1: Simple Lambda Function**\n",
    "```python\n",
    "square = lambda x: x ** 2\n",
    "print(square(5))  # Output: 25\n",
    "```\n",
    "\n",
    "##### **Example 2: Using Lambda with `map`**\n",
    "```python\n",
    "numbers = [1, 2, 3, 4]\n",
    "squared_numbers = list(map(lambda x: x ** 2, numbers))\n",
    "print(squared_numbers)  # Output: [1, 4, 9, 16]\n",
    "```\n",
    "\n",
    "##### **Example 3: Using Lambda with `filter`**\n",
    "```python\n",
    "numbers = [1, 2, 3, 4, 5, 6]\n",
    "even_numbers = list(filter(lambda x: x % 2 == 0, numbers))\n",
    "print(even_numbers)  # Output: [2, 4, 6]\n",
    "```\n",
    "\n",
    "\n",
    "##### **When to Use Lambda Functions?**\n",
    "- When you need a small function for a short period  \n",
    "- When using functions like `map()`, `filter()`, `sorted()`, and `reduce()`  \n",
    "- When defining a function inline for readability  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oJE9ZkY4ouWe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 549,
     "status": "ok",
     "timestamp": 1741267621241,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "oJE9ZkY4ouWe",
    "outputId": "f1da5622-2e40-46ba-bdcb-247a6869c24c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Alice', 85),\n",
       " ('Bob', 78),\n",
       " ('Charlie', 92),\n",
       " ('Alice', 88),\n",
       " ('Bob', 74),\n",
       " ('Charlie', 95),\n",
       " ('Alice', 90),\n",
       " ('Bob', 80),\n",
       " ('Charlie', 85)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract (Student, Score) pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DliNQVRCe6iK",
   "metadata": {
    "id": "DliNQVRCe6iK"
   },
   "source": [
    "By using the `student_scores_rdd` formed above we can use the students' names as a key and use the `reduceByKey()` function to sum the scores of each student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Wb05QjBuo3tD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 785,
     "status": "ok",
     "timestamp": 1741267652557,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "Wb05QjBuo3tD",
    "outputId": "38fc4a1e-f513-42d5-a2bc-1facf08e63b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Charlie', 272), ('Bob', 232), ('Alice', 263)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum scores per student\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QKPR_FvYpFf9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1741267753958,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "QKPR_FvYpFf9",
    "outputId": "8f39de4f-edf3-4190-bfbd-1c5669ce0b3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Charlie', 272), ('Alice', 263)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter students with total scores above 250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8oNSXusNotT7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1593,
     "status": "ok",
     "timestamp": 1741267768835,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "8oNSXusNotT7",
    "outputId": "f430b2fb-4082-40aa-d43b-79f2287124a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Charlie', 272), ('Alice', 263)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by total score in descending order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca649e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 102,
     "status": "ok",
     "timestamp": 1741260746871,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "2cca649e",
    "outputId": "fb253bb5-a991-4376-ae62-e9162ab9f598"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Alice', 'Math', 85),\n",
       " (2, 'Bob', 'Math', 78),\n",
       " (3, 'Charlie', 'Math', 92),\n",
       " (4, 'Alice', 'Science', 88),\n",
       " (5, 'Bob', 'Science', 74),\n",
       " (6, 'Charlie', 'Science', 95),\n",
       " (7, 'Alice', 'History', 90),\n",
       " (8, 'Bob', 'History', 80),\n",
       " (9, 'Charlie', 'History', 85)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a79fddc3",
   "metadata": {
    "id": "a79fddc3"
   },
   "source": [
    "#### Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4fe7a2",
   "metadata": {
    "id": "fd4fe7a2"
   },
   "source": [
    "Actions return a value after executing computations on the RDD.\n",
    "\n",
    "- **`collect()`** – Returns all elements of the RDD.\n",
    "- **`count()`** – Returns the number of elements.\n",
    "- **`first()`** – Returns the first element.\n",
    "- **`take(n)`** – Returns the first `n` elements.\n",
    "- **`top(n)`** – Returns the top `n` elements.\n",
    "- **`reduce(func)`** – Aggregates elements using `func`.\n",
    "- **`countByKey()`** – Counts occurrences of each key.\n",
    "- **`foreach(func)`** – Applies `func` to each element (without returning a new RDD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jQPJwVhKpqA6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2173,
     "status": "ok",
     "timestamp": 1741267872458,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "jQPJwVhKpqA6",
    "outputId": "ccc376e7-2901-47ca-8dec-4158af1d29ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Scores: [('Alice', 85), ('Bob', 78), ('Charlie', 92), ('Alice', 88), ('Bob', 74), ('Charlie', 95), ('Alice', 90), ('Bob', 80), ('Charlie', 85)]\n",
      "Aggregated Scores: [('Charlie', 272), ('Bob', 232), ('Alice', 263)]\n",
      "High Achievers: [('Charlie', 272), ('Alice', 263)]\n",
      "Sorted High Achievers: [('Charlie', 272), ('Alice', 263)]\n",
      "Total Number of Students: 3\n",
      "Top Scorer: ('Charlie', 272)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe5b0cf2",
   "metadata": {
    "id": "fe5b0cf2"
   },
   "source": [
    "---\n",
    "<a name=\"anchorDF\" style=\"position:absolute;\"></a>\n",
    "## 2.3 DataFrames\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ddb6bc",
   "metadata": {
    "id": "86ddb6bc"
   },
   "source": [
    "Like an RDD, a DataFrame is an immutable collection of data; however, unlike an RDD, data is organised by columns, like a table in a relational database. If you are familiar with dataframes in pandas, then you should have a good idea of the structure here. The difference between a pandas dataframe and a PySpark dataframe is that in Spark, dataframes are distributed in the cluster. Due to parallel execution on all cores on multiple machines, PySpark runs operations much faster than pandas. By allowing developers to impose a structure (& schema) on a collection of data, higher-level abstraction is also allowed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a270209a",
   "metadata": {
    "id": "a270209a"
   },
   "source": [
    "### **Creating a DataFrame**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d61208",
   "metadata": {
    "id": "54d61208"
   },
   "source": [
    "A dataframe can be created in several ways including: <br>\n",
    "- from an existing RDD\n",
    "- from a list\n",
    "- from an external data source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IJGa-mQLBaR0",
   "metadata": {
    "id": "IJGa-mQLBaR0"
   },
   "source": [
    "**From an existing RDD:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b18d72d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6239,
     "status": "ok",
     "timestamp": 1741268591825,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "0b18d72d",
    "outputId": "f070152b-4e0a-4b30-9630-44ff3a52db5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_1=1, _2='Alice', _3='Math', _4=85),\n",
       " Row(_1=2, _2='Bob', _3='Math', _4=78),\n",
       " Row(_1=3, _2='Charlie', _3='Math', _4=92),\n",
       " Row(_1=4, _2='Alice', _3='Science', _4=88),\n",
       " Row(_1=5, _2='Bob', _3='Science', _4=74),\n",
       " Row(_1=6, _2='Charlie', _3='Science', _4=95),\n",
       " Row(_1=7, _2='Alice', _3='History', _4=90),\n",
       " Row(_1=8, _2='Bob', _3='History', _4=80),\n",
       " Row(_1=9, _2='Charlie', _3='History', _4=85)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "rHFzJE_0BgTy",
   "metadata": {
    "id": "rHFzJE_0BgTy"
   },
   "source": [
    "**From a list:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d571a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1741268930975,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "b1d571a2",
    "outputId": "034609e7-61c6-484c-829e-dca19b75a753"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('John', '', 'Doe', '1998-04-08', 'M', 2000),\n",
       "  ('Michael', 'Williams', '', '2002-05-24', 'M', 3000),\n",
       "  ('James', '', 'Jones', '1981-09-09', 'M', 4000),\n",
       "  ('Maria', 'Anne', 'Jones', '1973-12-08', 'F', 4000),\n",
       "  ('Mary', 'Beth', 'Doe', '1985-02-13', 'F', -1)],\n",
       " ['firstname', 'middlename', 'lastname', 'dob', 'gender', 'salary'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = [('John','','Doe','1998-04-08','M',2000),\n",
    "  ('Michael','Williams','','2002-05-24','M',3000),\n",
    "  ('James','','Jones','1981-09-09','M',4000),\n",
    "  ('Maria','Anne','Jones','1973-12-08','F',4000),\n",
    "  ('Mary','Beth','Doe','1985-02-13','F',-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2070daed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1741268935536,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "2070daed",
    "outputId": "170cde8e-bc93-49e1-fc30-1aeecbd26d59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[firstname: string, middlename: string, lastname: string, dob: string, gender: string, salary: bigint]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c1a933",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 566,
     "status": "ok",
     "timestamp": 1741268938984,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "07c1a933",
    "outputId": "81a1f732-4f91-496b-97de-2f81660a134a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(firstname='John', middlename='', lastname='Doe', dob='1998-04-08', gender='M', salary=2000),\n",
       " Row(firstname='Michael', middlename='Williams', lastname='', dob='2002-05-24', gender='M', salary=3000),\n",
       " Row(firstname='James', middlename='', lastname='Jones', dob='1981-09-09', gender='M', salary=4000),\n",
       " Row(firstname='Maria', middlename='Anne', lastname='Jones', dob='1973-12-08', gender='F', salary=4000),\n",
       " Row(firstname='Mary', middlename='Beth', lastname='Doe', dob='1985-02-13', gender='F', salary=-1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf199051",
   "metadata": {
    "id": "cf199051"
   },
   "source": [
    "**Reading External Data:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FzH-yKu82nVx",
   "metadata": {
    "id": "FzH-yKu82nVx"
   },
   "source": [
    "**Double check that the `people.json` file is uploaded into the Files area** - upload again now if it is not (refer to the start of the notebook if you need a refresh on how to upload)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8be1874",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3271,
     "status": "ok",
     "timestamp": 1741269004271,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "b8be1874",
    "outputId": "8f508911-a2c7-4b05-a135-570c7b385090"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=None, name='Michael'),\n",
       " Row(age=30, name='Andy'),\n",
       " Row(age=19, name='Justin')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##External data:\n",
    "df_from_json = spark.read.json('../DataSources/people.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cfd0e3",
   "metadata": {
    "id": "92cfd0e3"
   },
   "source": [
    "We will cover more ways to read in external data later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ab3c2",
   "metadata": {
    "id": "cc9ab3c2"
   },
   "source": [
    "### **Basic Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ae081a",
   "metadata": {
    "id": "36ae081a"
   },
   "source": [
    "**Showing the data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62de3f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1741269025370,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "a62de3f1",
    "outputId": "8dfdaa79-4e46-4643-ba68-eb3b946e8f08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+---+\n",
      "| _1|     _2|     _3| _4|\n",
      "+---+-------+-------+---+\n",
      "|  1|  Alice|   Math| 85|\n",
      "|  2|    Bob|   Math| 78|\n",
      "|  3|Charlie|   Math| 92|\n",
      "|  4|  Alice|Science| 88|\n",
      "|  5|    Bob|Science| 74|\n",
      "|  6|Charlie|Science| 95|\n",
      "|  7|  Alice|History| 90|\n",
      "|  8|    Bob|History| 80|\n",
      "|  9|Charlie|History| 85|\n",
      "+---+-------+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2889674",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 795,
     "status": "ok",
     "timestamp": 1741269031034,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "c2889674",
    "outputId": "3fdc6b84-295a-4a15-8728-8ed4225944fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "|     John|          |     Doe|1998-04-08|     M|  2000|\n",
      "|  Michael|  Williams|        |2002-05-24|     M|  3000|\n",
      "|    James|          |   Jones|1981-09-09|     M|  4000|\n",
      "|    Maria|      Anne|   Jones|1973-12-08|     F|  4000|\n",
      "|     Mary|      Beth|     Doe|1985-02-13|     F|    -1|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "625e94b7",
   "metadata": {
    "id": "625e94b7"
   },
   "source": [
    "**Looking at data architecture:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf90a2c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1741269035429,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "cf90a2c4",
    "outputId": "fb1365d8-0394-4842-b3ae-756014de0078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be77a45a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1741269040045,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "be77a45a",
    "outputId": "96464817-46c7-43c4-88dc-5e5621929a83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b46c51b",
   "metadata": {
    "id": "5b46c51b"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> printSchema() is similar to .info() in pandas.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KpbOY6yzFrvi",
   "metadata": {
    "id": "KpbOY6yzFrvi"
   },
   "source": [
    "**Getting the column names with `.columns`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a27f816",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1741269047289,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "7a27f816",
    "outputId": "c0efb523-a621-4ed5-c48f-7c2a15e57e72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_1', '_2', '_3', '_4']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9969f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1741269049624,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "3e9969f7",
    "outputId": "8337d28f-4fba-40e4-ac1e-9c90e6898c47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['firstname', 'middlename', 'lastname', 'dob', 'gender', 'salary']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81a43ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1741269052544,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "d81a43ff",
    "outputId": "3c2062c3-69a6-4370-b8e4-5a35ca81ab79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'name']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "UG-BXUqrFgUH",
   "metadata": {
    "id": "UG-BXUqrFgUH"
   },
   "source": [
    "**Get a brief description of data with `.describe()`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b113844",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1741269064303,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "1b113844",
    "outputId": "676ca8f8-8526-4ad8-c70f-7ffa565ca2c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, age: string, name: string]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d572b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122,
     "status": "ok",
     "timestamp": 1741269067024,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "e5d572b6",
    "outputId": "0dafbdbc-e977-4422-c5ab-c144338ab8bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, firstname: string, middlename: string, lastname: string, dob: string, gender: string, salary: string]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d997af33",
   "metadata": {
    "id": "d997af33"
   },
   "source": [
    "Notice how in our `df_from_json` dataframe age is of the type string. Some data types make it easier to infer schema (like tabular formats such as csv which we will show later). <br> However, you often have to set the schema yourself if you aren't dealing with a .read method that doesn't have inferSchema() built-in. This can be handled easily as spark has all the tools you need for this, it just requires a very specific structure:\n",
    "\n",
    "Reference: https://spark.apache.org/docs/latest/sql-ref-datatypes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IIFTNz8fw0pR",
   "metadata": {
    "id": "IIFTNz8fw0pR"
   },
   "source": [
    "**StructField:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec5206e7",
   "metadata": {
    "id": "ec5206e7"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField, StringType, IntegerType, StructType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd90208",
   "metadata": {
    "id": "ddd90208"
   },
   "source": [
    "When defining a schema for a PySpark DataFrame, we use `StructType` and `StructField` to specify the structure of the data. Each column in the DataFrame is represented by a `StructField`.\n",
    "\n",
    "Each `StructField` takes the following parameters:\n",
    "- `name`: string, name of the field.\n",
    "- `dataType`: class, DataType of the field.\n",
    "- `nullable`: boolean, whether the field can be null (None) or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19e6ce00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1741270004712,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "19e6ce00",
    "outputId": "1650e244-ece9-4a36-93ae-4d56c48094e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructField('age', IntegerType(), True),\n",
       " StructField('name', StringType(), True)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data_schema = [StructField(\"age\", IntegerType(), True),\n",
    "                    StructField(\"name\", StringType(), True)]\n",
    "json_data_schema ##List with the values we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b6006b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1741270007712,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "7b6006b9",
    "outputId": "47efbffb-2957-41f9-e916-3d85784379ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('age', IntegerType(), True), StructField('name', StringType(), True)])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_struc = StructType(fields=json_data_schema)\n",
    "final_struc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8378c34",
   "metadata": {
    "id": "f8378c34"
   },
   "source": [
    "Now, we can read in the json file with the defined schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce6c7c92",
   "metadata": {
    "id": "ce6c7c92"
   },
   "outputs": [],
   "source": [
    "# Read the people.json file with the new schema\n",
    "df_from_json_schemed = spark.read.json('../DataSources/people.json', schema=final_struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43cde81c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1741270022153,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "43cde81c",
    "outputId": "8643c00d-3d84-4170-9577-d875dee9cb83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, name: string]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_from_json_schemed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WMVajLTwIOd2",
   "metadata": {
    "id": "WMVajLTwIOd2"
   },
   "source": [
    "**Creating a copy of `df_from_json_schemed` as `df`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a55377d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1741271080569,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "4a55377d",
    "outputId": "3dd143fe-bc35-4587-86e6-e972af8bfc6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, name: string]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "lwoXBtydImkE",
   "metadata": {
    "id": "lwoXBtydImkE"
   },
   "source": [
    "**Ensuring that the copy is independent and not an alias:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gpsN0RlV1up2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1741271088068,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "gpsN0RlV1up2",
    "outputId": "38544859-37eb-41bd-d776-5551587361ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1829892560144, 1829892871296, False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb4e2b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "ok",
     "timestamp": 1741271097935,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "fdb4e2b5",
    "outputId": "ae946dff-8689-49ef-a218-51e582c44fad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|NULL|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769e98f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1741271103171,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "769e98f4",
    "outputId": "b792c165-8a1c-42f1-c941-5e094ce5ce5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'age'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grabbing a column object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44432757",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1741271107373,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "44432757",
    "outputId": "63add178-707c-4268-963d-c56a3da89000"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validating the object type`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5ec2c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1741271110930,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "8a5ec2c4",
    "outputId": "667555cc-e0b6-4129-ac30-6aff9c1e80d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6bb162e",
   "metadata": {
    "id": "d6bb162e"
   },
   "source": [
    "**NOTE**: Notice how using select returns a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39abdde",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 186
    },
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1741271116754,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "f39abdde",
    "outputId": "add5c0dd-5e10-48dd-fbbb-3fab3c3330b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16cf63ea",
   "metadata": {
    "id": "16cf63ea"
   },
   "source": [
    " __show() vs collect() vs take()__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olQjv2t3MAjY",
   "metadata": {
    "id": "olQjv2t3MAjY"
   },
   "source": [
    "Key Differences:\n",
    "- `show()`: For quick viewing (prints data).\n",
    "- `collect()`: Retrieves the entire dataset (be careful with large datasets).\n",
    "- `take()`: Retrieves a specific number of rows as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e23fe6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17e23fe6",
    "outputId": "96eddcfa-d253-4d15-9ab2-028e6ac89e91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| age|\n",
      "+----+\n",
      "|NULL|\n",
      "|  30|\n",
      "|  19|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##will display the dataframe in tabular form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b49b22c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "ok",
     "timestamp": 1741271324701,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "4b49b22c",
    "outputId": "f26d04ec-0c54-4476-b39d-65f1ceac9c45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=None), Row(age=30), Row(age=19)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ##Will display content and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a5ed4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 140,
     "status": "ok",
     "timestamp": 1741271325535,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "d1a5ed4a",
    "outputId": "845ccb3e-db69-4717-b1a4-623fcf840656"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=None), Row(age=30)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ##will display a the content and metadata of a limited number of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7zK_q4HzMwit",
   "metadata": {
    "id": "7zK_q4HzMwit"
   },
   "source": [
    "Return a list of Row objects with `head()` and `tail()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4390fcf5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1741271414768,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "4390fcf5",
    "outputId": "8c17dfc9-d7ea-4caa-c001-350c9342e4f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=None, name='Michael'), Row(age=30, name='Andy')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of Row objects from the top of the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8462c94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 138,
     "status": "ok",
     "timestamp": 1741271416307,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "e8462c94",
    "outputId": "752cb6b5-8e8a-457d-98f5-e54da0fa7202"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age=30, name='Andy'), Row(age=19, name='Justin')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of Row objects from the bottom of the DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ece3ab",
   "metadata": {
    "id": "81ece3ab"
   },
   "source": [
    "**Selecting Multiple Columns:**\n",
    "\n",
    "Reference: https://spark.apache.org/docs/3.1.1/api/python/reference/api/pyspark.sql.DataFrame.select.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4438892",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1741271451767,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "d4438892",
    "outputId": "956c26e9-12ef-424b-f146-74c63662153a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, name: string]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47cc3df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1741271452617,
     "user": {
      "displayName": "Sinead Quigley",
      "userId": "09113376899917135625"
     },
     "user_tz": 0
    },
    "id": "a47cc3df",
    "outputId": "e62e90da-ea60-435e-ec7e-96e6838b4145"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|NULL|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb50ece8",
   "metadata": {
    "id": "cb50ece8"
   },
   "source": [
    "**Creating New Columns**\n",
    "\n",
    "Reference: https://spark.apache.org/docs/3.1.1/api/python/reference/pyspark.sql.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9f91d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d9f91d4",
    "outputId": "3b29e8f9-bd31-4a9b-ec12-06f982689ed5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|supernewage|   name|\n",
      "+-----------+-------+\n",
      "|       NULL|Michael|\n",
      "|         30|   Andy|\n",
      "|         19| Justin|\n",
      "+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simple Rename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7310c186",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7310c186",
    "outputId": "1204a27b-44a3-4ff2-b659-c2e61066564b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|NULL|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "yfc4c3GpQvaU",
   "metadata": {
    "id": "yfc4c3GpQvaU"
   },
   "source": [
    "**Note:** These changes aren't permanent unless you assign it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a64123f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6a64123f",
    "outputId": "40923d88-c9df-49f5-feec-24f0f0e63043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+------+\n",
      "| age|   name|newage|\n",
      "+----+-------+------+\n",
      "|NULL|Michael|  NULL|\n",
      "|  30|   Andy|    30|\n",
      "|  19| Justin|    19|\n",
      "+----+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding a new column with a simple copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92478bcb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92478bcb",
    "outputId": "6b3b0d44-9255-463c-f9ad-54ff5da352b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---------+\n",
      "| age|   name|doubleage|\n",
      "+----+-------+---------+\n",
      "|NULL|Michael|     NULL|\n",
      "|  30|   Andy|       60|\n",
      "|  19| Justin|       38|\n",
      "+----+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#New column with some transformation: double the age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "04d99fa3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04d99fa3",
    "outputId": "c9465789-e000-4963-974b-0afe33313f3a"
   },
   "outputs": [],
   "source": [
    "#***Task***\n",
    "# Add a new column with some transformation: age + 1\n",
    "\n",
    "#-----------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d269d0c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d269d0c1",
    "outputId": "52307934-2656-457b-b9a6-18c534e9cca0"
   },
   "outputs": [],
   "source": [
    "#***Task***\n",
    "# Add a new column with some transformation: age/2\n",
    "\n",
    "#---------------------------------------------------------------#\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e2385d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0e2385d",
    "outputId": "b00f7745-9484-4e5c-c710-cd50db19b07d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+--------+\n",
      "| age|   name|half_age|\n",
      "+----+-------+--------+\n",
      "|NULL|Michael|    NULL|\n",
      "|  30|   Andy|    15.0|\n",
      "|  19| Justin|     9.5|\n",
      "+----+-------+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 1829892559520, 1829892560144)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0989e268",
   "metadata": {
    "id": "0989e268"
   },
   "source": [
    "<a name=\"anchorConclusion\" style=\"position:absolute;\"></a>\n",
    "<hr style=\"border:0.5px solid\", color= \"gray\">\n",
    "\n",
    "# 4. Conclusion\n",
    "<hr style=\"border-top:1px dashed\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b73e52",
   "metadata": {
    "id": "a4b73e52"
   },
   "source": [
    "- PySpark is a powerful language for Data Science Analysts to learn, because it enables scalabe data wrangling and analysis beyond the limitations of pandas.\n",
    "- If you already know Python, Pandas and SQL this should be a great jump into big data.\n",
    "- If you are interested in Data Engineering, [Azure Databricks](https://docs.microsoft.com/en-us/azure/databricks/languages/python) uses PySpark as one of the primary languages to interact with data.\n",
    "- For more information read the [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/getting_started/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4265ee6e",
   "metadata": {
    "id": "4265ee6e"
   },
   "source": [
    "## Citations\n",
    "<a name=\"KDNuggets\" style=\"position:absolute;\"></a>\n",
    "7 Steps to Mastering Apache 2.0 :cite:p:[2016:KDNuggets](https://www.kdnuggets.com/2016/09/7-steps-mastering-apache-spark.html)\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "7_jeTiutrdUC",
    "4265ee6e"
   ],
   "provenance": [
    {
     "file_id": "16KdujP5oY2nmi4R558eKHBTQFl7cDLch",
     "timestamp": 1746538565774
    }
   ],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "cbs_dataeng_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
